import torch
import glob
import time
import numpy as np
from pathlib import Path
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import SimpleITK as sitk
import matplotlib.pyplot as plt
from sklearn.preprocessing import OneHotEncoder
from torch.utils.data import DataLoader, Dataset
from torchvision.transforms import ToTensor

from data_preprocessing.log_worker import add_info_logging

global_loss_sum = [0, 0, 0, 0, 0]


def compute_per_channel_dice_3D(input, target, epsilon=1e-6, weight=None):
    """
    Computes DiceCoefficient as defined in https://arxiv.org/abs/1606.04797 given  a multi channel input and target.
    Assumes the input is a normalized probability, e.g. a result of Sigmoid or Softmax function.
    Args:
            input (torch.Tensor): NxCxSpatial input tensor
            target (torch.Tensor): NxCxSpatial target tensor
            epsilon (float): prevents division by zero
            weight (torch.Tensor): Cx1 tensor of weight per channel/class
    """

    def flatten(tensor):
        """Flattens a given tensor such that the channel axis is first.
        The shapes are transformed as follows:
            (N, C, D, H, W) -> (C, N * D * H * W)
        """
        # number of channels
        C = tensor.size(1)
        # new axis order
        # –ú–µ–Ω—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –æ—Å–µ–π, —á—Ç–æ–±—ã –∫–∞–Ω–∞–ª—ã –±—ã–ª–∏ –ø–µ—Ä–≤—ã–º–∏
        axis_order = (1, 0) + tuple(range(2, tensor.dim()))
        # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)
        # –ü–µ—Ä–µ—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ—Å–µ–π –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –¥–≤—É–º–µ—Ä–Ω—ã–π —Ç–µ–Ω–∑–æ—Ä
        transposed = tensor.permute(axis_order)
        # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)
        return transposed.contiguous().view(C, -1)

    # input and target shapes must match
    assert input.size() == target.size(), "'input' and 'target' must have the same shape"

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤
    input = flatten(input) # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    target = flatten(target).float() # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –º–µ—Ç–∫–∏ –≤ float

    # compute per channel Dice Coefficient
    # –í—ã—á–∏—Å–ª—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ (–ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ) –º–µ–∂–¥—É input –∏ target
    intersect = (input * target).sum(-1)
    if weight is not None:
        intersect = weight * intersect

    # here we can use standard dice (input + target).sum(-1) or extension (see V-Net) (input^2 + target^2).sum(-1)
    # –í—ã—á–∏—Å–ª—è–µ–º –∑–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å: —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ input –∏ target
    denominator = (input * input).sum(-1) + (target * target).sum(-1)
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç Dice –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–∞–Ω–∞–ª–∞
    return 2 * (intersect / denominator.clamp(min=epsilon))


class DiceCoefficientMetric:
    """Computes Dice Coefficient.
    Generalized to multiple channels by computing per-channel Dice Score
    (as described in https://arxiv.org/pdf/1707.03237.pdf) and theTn simply taking the average.
    Input is expected to be probabilities instead of logits.
    This metric is mostly useful when channels contain the same semantic class (e.g. affinities computed with different offsets).
    DO NOT USE this metric when training with DiceLoss, otherwise the results will be biased towards the loss.
    """

    def __init__(self, epsilon=1e-6, **kwargs):
        self.epsilon = epsilon

    def __call__(self, input, target):
        # Average across channels in order to get the final score
        return torch.mean(compute_per_channel_dice_3D(input, target, epsilon=self.epsilon))


class DiceLoss(nn.Module):
    """Computes Dice Loss according to https://arxiv.org/abs/1606.04797.
    For multi-class segmentation `weight` parameter can be used to assign different weights per class.
    """

    def __init__(self):
        super().__init__()

    # def forward(self, input, target):
    #     # get probabilities from logits
    #     # normalization = nn.Sigmoid()
    #     # input = normalization(input)
    #
    #     # compute Dice score across all channels/classes
    #     input = torch.softmax(input, dim=1)  # –ü—Ä–∏–º–µ–Ω—è–µ–º Softmax –ø–µ—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º Dice
    #     per_channel_dice = self.dice(input, target)
    #     # global_loss_sum[0] += float(per_channel_dice[0].detach().numpy())
    #     # global_loss_sum[1] += float(per_channel_dice[1].detach().numpy())
    #     # global_loss_sum[2] += float(per_channel_dice[2].detach().numpy())
    #     # global_loss_sum[3] += float(per_channel_dice[3].detach().numpy())
    #     # global_loss_sum[4] += 1
    #     return 1. - torch.mean(per_channel_dice)

    def forward(self, input, target):
        input = torch.softmax(input, dim=1)  # Softmax –¥–ª—è –ª–æ–≥–∏—Ç–æ–≤
        target_one_hot = F.one_hot(target, num_classes=input.shape[1])  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º target –≤ one-hot
        target_one_hot = target_one_hot.permute(0, 4, 1, 2, 3).float()  # –ü—Ä–∏–≤–æ–¥–∏–º –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç

        per_channel_dice = compute_per_channel_dice_3D(input, target_one_hot)
        return 1. - torch.mean(per_channel_dice)

    def dice(self, input, target):
        return compute_per_channel_dice_3D(input, target)


class BCEDiceLoss(nn.Module):
    """Linear combination of BCE and Dice losses"""

    def __init__(self, alpha=0.25, beta=0.75):
        super(BCEDiceLoss, self).__init__()
        self.alpha = alpha
        self.bce = nn.BCEWithLogitsLoss()
        # self.bce = nn.BCELoss()
        self.beta = beta
        self.dice = self.DiceLoss()
        t = 0

    def forward(self, input, target):
        return self.alpha * self.bce(input, target.double()) + self.beta * self.dice(input, target)


class DoubleConv3D(nn.Module):
    """(convolution => [BN] => ReLU) * 2"""

    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv3d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm3d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv3d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        add_info_logging(f"Shape of x: {x.shape}")
        return self.double_conv(x)


class Down3D(nn.Module):
    """Downscaling with maxpool then double conv"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool3d(2),
            DoubleConv3D(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)


class Up3D(nn.Module):
    """Upscaling then double conv"""

    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()

        # if bilinear, use the normal convolutions to reduce the number of channels
        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=True)
            self.conv = DoubleConv3D(in_channels, out_channels, in_channels // 2)
        else:
            self.up = nn.ConvTranspose3d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv3D(in_channels, out_channels)

    def forward(self, x1, x2):
        # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ç–µ–Ω–∑–æ—Ä–∞ x1
        x1 = self.up(x1)

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞–∑–Ω–∏—Ü—ã –ø–æ –≥–ª—É–±–∏–Ω–µ, –≤—ã—Å–æ—Ç–µ –∏ —à–∏—Ä–∏–Ω–µ
        diffZ = x2.size(2) - x1.size(2)  # –†–∞–∑–Ω–∏—Ü–∞ –ø–æ –≥–ª—É–±–∏–Ω–µ
        diffY = x2.size(3) - x1.size(3)  # –†–∞–∑–Ω–∏—Ü–∞ –ø–æ –≤—ã—Å–æ—Ç–µ
        diffX = x2.size(4) - x1.size(4)  # –†–∞–∑–Ω–∏—Ü–∞ –ø–æ —à–∏—Ä–∏–Ω–µ

        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ x1 —Å —É—á—ë—Ç–æ–º —Ä–∞–∑–Ω–∏—Ü—ã —Ä–∞–∑–º–µ—Ä–æ–≤
        x1 = F.pad(
            x1,
            [diffX // 2, diffX - diffX // 2,  # –®–∏—Ä–∏–Ω–∞ (X)
             diffY // 2, diffY - diffY // 2,  # –í—ã—Å–æ—Ç–∞ (Y)
             diffZ // 2, diffZ - diffZ // 2]  # –ì–ª—É–±–∏–Ω–∞ (Z)
        )

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º x1 –∏ x2 –ø–æ –æ—Å–∏ –∫–∞–Ω–∞–ª–æ–≤
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


class OutConv3D(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(OutConv3D, self).__init__()
        self.conv = nn.Conv3d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)


class UNet3D(nn.Module):
    def __init__(self, n_channels, n_classes, dropout=0.25, multiplier=8, bilinear=False):
        super(UNet3D, self).__init__()
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.bilinear = bilinear

        # –ë–∞–∑–æ–≤—ã–π –º–Ω–æ–∂–∏—Ç–µ–ª—å –∫–∞–Ω–∞–ª–æ–≤
        self.inc = DoubleConv3D(n_channels, 4 * multiplier)  # –í—Ö–æ–¥–Ω–æ–π –±–ª–æ–∫
        self.down1 = Down3D(4 * multiplier, 8 * multiplier)  # –ü–µ—Ä–≤—ã–π —É—Ä–æ–≤–µ–Ω—å
        self.down2 = Down3D(8 * multiplier, 16 * multiplier)  # –í—Ç–æ—Ä–æ–π —É—Ä–æ–≤–µ–Ω—å
        self.down3 = Down3D(16 * multiplier, 32 * multiplier)  # –¢—Ä–µ—Ç–∏–π —É—Ä–æ–≤–µ–Ω—å

        factor = 2 if bilinear else 1
        self.down4 = Down3D(32 * multiplier, 64 * multiplier // factor)  # –ß–µ—Ç–≤—ë—Ä—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å

        self.up1 = Up3D(64 * multiplier, 32 * multiplier // factor, bilinear)  # –ü–µ—Ä–≤—ã–π –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥
        self.up2 = Up3D(32 * multiplier, 16 * multiplier // factor, bilinear)  # –í—Ç–æ—Ä–æ–π –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥
        self.up3 = Up3D(16 * multiplier, 8 * multiplier // factor, bilinear)  # –¢—Ä–µ—Ç–∏–π –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥
        self.up4 = Up3D(8 * multiplier, 8 * multiplier, bilinear)  # –ß–µ—Ç–≤—ë—Ä—Ç—ã–π –∞–ø—Å–∫–µ–π–ª–∏–Ω–≥

        self.outc = OutConv3D(8 * multiplier, n_classes)  # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–ª–æ–π
        self.final_activation = nn.Softmax(dim=1)  # –î–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π –∑–∞–¥–∞—á–∏

    def forward(self, input):
        # –ü—Ä—è–º–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —Å–ª–æ–∏
        x1 = self.inc(input)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)

        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        x = self.outc(x)
        logits = self.final_activation(x)
        return logits

    def use_checkpointing(self):
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏
        self.inc = torch.utils.checkpoint(self.inc)
        self.down1 = torch.utils.checkpoint(self.down1)
        self.down2 = torch.utils.checkpoint(self.down2)
        self.down3 = torch.utils.checkpoint(self.down3)
        self.down4 = torch.utils.checkpoint(self.down4)
        self.up1 = torch.utils.checkpoint(self.up1)
        self.up2 = torch.utils.checkpoint(self.up2)
        self.up3 = torch.utils.checkpoint(self.up3)
        self.up4 = torch.utils.checkpoint(self.up4)
        self.outc = torch.utils.checkpoint(self.outc)


class UNet3DTrainer:

    def __init__(self, n_classes=4, learning_rate=0.0001, weight_decay=0.01, epochs=300):
        self.model = UNet3D(n_channels=1, n_classes=n_classes).float()
        self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate, weight_decay=weight_decay)
        # self.loss_criterion = DiceLoss()
        self.loss_criterion = nn.CrossEntropyLoss()
        self.eval_criterion = DiceCoefficientMetric()
        self.epochs = epochs

    def __move_to_device(self, input, device):
        if isinstance(input, tuple) or isinstance(input, list):
            return tuple([self.__move_to_device(x) for x in input])
        else:
            return torch.from_numpy(input).to(device)

    def __generate_result(self, input, mask):
        input_sitk = sitk.GetImageFromArray(input)
        # mask_united = np.zeros((mask.shape[1], mask.shape[2]))
        # for t in range(0, mask.shape[0]):
        #    mask_united[mask[t, :, :] >= 0.5] = t + 1
        # mask_united = mask[1, :, :] + mask[2, :, :] + mask[3, :, :] + mask[0, :, :]
        # –î–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –º–∞—Å–æ–∫ –≤ 3D
        mask_united = mask.argmax(axis=0)  # –°—É–º–º–∏—Ä—É–µ–º –≤–¥–æ–ª—å –æ—Å–∏ –∫–ª–∞—Å—Å–æ–≤
        mask_sitk = sitk.GetImageFromArray(mask_united)
        return input_sitk, mask_sitk

    def train(self, train_dl, valid_dl, model_file):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(device)  # –ü–µ—Ä–µ–Ω–æ—Å –º–æ–¥–µ–ª–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ

        best_acc = 0.0

        start = time.time()
        train_loss, valid_loss = [], []

        for epoch in range(self.epochs):
            add_info_logging('Epoch {}/{}'.format(epoch, self.epochs - 1))
            add_info_logging('-' * 10)

            for phase in ['train', 'valid']:
                if phase == 'train':
                    self.model.train()  # –í–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è
                    dataloader = train_dl
                else:
                    self.model.eval()  # –í–∫–ª—é—á–∞–µ–º —Ä–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                    dataloader = valid_dl

                running_loss = 0.0
                running_acc = 0.0

                for step, (x, y) in enumerate(dataloader):
                    x = x.float()
                    y = y.float()
                    # –ü–µ—Ä–µ–Ω–æ—Å –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                    add_info_logging(f"Shape of x: {x.shape}")
                    x = x.to(device)
                    y = y.to(device)

                    # Forward pass
                    if phase == 'train':
                        self.optimizer.zero_grad()  # –û–±–Ω—É–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
                        outputs = self.model(x)  # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                        loss = self.loss_criterion(outputs, y)  # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å
                        loss.backward()  # Backward pass
                        self.optimizer.step()  # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                    else:
                        with torch.no_grad():  # –û—Ç–∫–ª—é—á–∞–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
                            outputs = self.model(x)
                            loss = self.loss_criterion(outputs, y)

                    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
                    acc = self.eval_criterion(outputs, y)
                    running_loss += loss.item() * x.size(0)  # –°—É–º–º–∞ –ø–æ—Ç–µ—Ä—å –∑–∞ –±–∞—Ç—á
                    running_acc += acc.item() * x.size(0)  # –°—É–º–º–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∑–∞ –±–∞—Ç—á

                    if step % 5 == 0:
                        add_info_logging(f'Step {step}: Loss = {loss.item():.4f}, Acc = {acc.item():.4f}')

                # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∑–∞ —ç–ø–æ—Ö—É
                epoch_loss = running_loss / len(dataloader.dataset)
                epoch_acc = running_acc / len(dataloader.dataset)

                add_info_logging(f'{phase} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å
                if phase == 'train':
                    train_loss.append(epoch_loss)
                else:
                    valid_loss.append(epoch_loss)

                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
                # if phase == 'valid' and epoch_acc > max(valid_loss, default=0):
                #     torch.save(self.model.state_dict(), model_file)
                if phase == 'valid' and epoch_acc > best_acc:
                    best_acc = epoch_acc
                    torch.save(self.model.state_dict(), model_file)

        time_elapsed = time.time() - start
        add_info_logging('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))
        torch.save(self.model.state_dict(), model_file + '_final.pth')

        return train_loss, valid_loss

    def test(self, test_dl, case_names, model_file, results_folder):
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.load_state_dict(torch.load(model_file, map_location=device))  # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å
        self.model.to(device)  # –ü–µ—Ä–µ–Ω–æ—Å –º–æ–¥–µ–ª–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        self.model.eval()  # –ü–µ—Ä–µ–≤–æ–¥ –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

        start = time.time()  # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è

        global_count = 0  # –°—á—ë—Ç—á–∏–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤

        with torch.no_grad():  # –û—Ç–∫–ª—é—á–∞–µ–º –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
            for x, y in test_dl:
                x = x.float()
                y = y.float()
                # –ü–µ—Ä–µ–Ω–æ—Å –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                x = x.to(device)
                y = y.to(device)

                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
                outputs = self.model(x)
                outputs_np = outputs.cpu().numpy()  # –ü–µ—Ä–µ–≤–æ–¥ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –≤ NumPy
                x_np = x.cpu().numpy()  # –ü–µ—Ä–µ–≤–æ–¥ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ NumPy
                y_np = y.cpu().numpy()  # –ü–µ—Ä–µ–≤–æ–¥ –∏—Å—Ç–∏–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –≤ NumPy

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤ –±–∞—Ç—á–µ
                for t in range(outputs_np.shape[0]):  # –¶–∏–∫–ª –ø–æ –ø—Ä–∏–º–µ—Ä–∞–º –≤ –±–∞—Ç—á–µ
                    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç SimpleITK
                    input_sitk, mask_sitk = self.__generate_result(x_np[t, 0, :, :, :], outputs_np[t, 0, :, :, :])

                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    input_path = f"{results_folder}/im_{case_names[global_count]}.nii.gz"
                    sitk.WriteImage(input_sitk, input_path)

                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π –º–∞—Å–∫–∏
                    mask_path = f"{results_folder}/mask_{case_names[global_count]}.nii.gz"
                    sitk.WriteImage(mask_sitk, mask_path)

                    print(f"Saved results for case: {case_names[global_count]}")  # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

                    global_count += 1  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫

        time_elapsed = time.time() - start  # –ó–∞—Å–µ–∫–∞–µ–º –≤—Ä–µ–º—è
        print(f"Testing complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s")

    def test_framework(self, slices, model_file):

        self.model.load_state_dict(torch.load(model_file))
        # self.model.eval()
        # self.model.cuda()

        global_count = 0
        slices_t = torch.tensor(slices.astype(float))
        slices_t = torch.unsqueeze(slices_t, 1)
        with torch.no_grad():
            output = self.model(slices_t).numpy()
            # results.append(output.numpy())

        # plt.imshow(output[2, 0, :, :])
        # plt.show()

        # plt.imshow(output[2, 1, :, :])
        # plt.show()

        # plt.imshow(output[2, 2, :, :])
        # plt.show()

        # plt.imshow(output[2, 3, :, :])
        # plt.show()
        return output


class WrapperUnet:

    @staticmethod
    def try_unet3d_training(folder):
        loader = DataloaderSeg3D(folder + '/data')
        loader.generate_data_loaders(0.15, 2)

        trainer = UNet3DTrainer()
        trainer.train(loader.train_dl, loader.valid_dl, folder + '/models/model_weights.pth')

    @staticmethod
    def try_unet3d_testing(folder):
        loader = DataloaderSeg3D(folder + '/test_data')
        loader.generate_data_loaders(0, 2)

        trainer = UNet3DTrainer()
        trainer.test(loader.test_dl, loader.case_names,
                     folder + '/models/model_weights.pth', folder + '/results')


class DataloaderSeg3D:

    def __init__(self, data_folder):
        subfolders = glob.glob(data_folder + '/*')
        self.database = DatabaseImSegNII(subfolders)
        self.case_names = []
        for subfolder in subfolders:
            self.case_names.append(Path(subfolder).parts[-1])

    def generate_data_loaders(self, valid_prop, batch_size, shuffle=True):
        if valid_prop > 0:
            valid_num = int(valid_prop * len(self.database))
            train_ds, valid_ds = torch.utils.data.random_split(self.database,
                                                               (len(self.database) - valid_num, valid_num))
            self.train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=shuffle)
            self.valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=shuffle)
        else:
            self.test_dl = DataLoader(self.database, batch_size=batch_size)


class DatabaseImSegNII(Dataset):

    def __init__(self, subfolders):
        self.images = []
        self.masks = []
        self.transform = ToTensor()
        for i in range(0, len(subfolders)):
            self.images.append(self._load_nii(Path(subfolders[i]) / "image.nii.gz"))
            self.masks.append(self._load_nii(Path(subfolders[i]) / "mask.nii.gz"))
        if len(self.images) > 0:
            self.normalize_images()

    def normalize_images(self):
        minF = np.amin(self.images[0])
        maxF = np.amax(self.images[0])
        for i in range(1, len(self.images)):
            minF = min(minF, np.amin(self.images[i]))
            maxF = max(maxF, np.amax(self.images[i])) # min(maxF, np.amax(self.images[0]))
        # minF = np.amin(np.array(self.images))
        # maxF = np.amax(np.array(self.images))

        for i in range(0, len(self.images)):
            self.images[i] = ((self.images[i] - minF)/(maxF - minF)).astype(np.float32)

    def _load_nii(self, file_path):
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª .nii.gz –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –≤–∏–¥–µ NumPy –º–∞—Å—Å–∏–≤–∞.
        """
        itk_image = sitk.ReadImage(file_path)  # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ —Å –ø–æ–º–æ—â—å—é SimpleITK
        image = sitk.GetArrayFromImage(itk_image)  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ NumPy –º–∞—Å—Å–∏–≤
        return image

    def __len__(self):
        return len(self.images)

    def __getitem__(self, idx):
        # img = self.images[idx]
        # mask = self.masks[idx]
        #
        # # add_info_logging(f"üîπ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx}: img.shape={img.shape} mask.shape={mask.shape}")
        # return self.transform(self.images[idx]), torch.tensor(self.masks[idx], dtype=torch.long)
        img = self.images[idx]
        mask = self.masks[idx]
        add_info_logging(f"üîπ –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {idx}: img.shape={img.shape} mask.shape={mask.shape}")

        # üîπ –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–º–µ–µ—Ç 3 –æ—Å–∏ (D, H, W), –¥–æ–±–∞–≤–ª—è–µ–º –æ—Å—å –∫–∞–Ω–∞–ª–∞
        if len(img.shape) == 3:
            img = img[np.newaxis, :, :, :]  # –¢–µ–ø–µ—Ä—å (1, D, H, W)

        img = torch.tensor(img, dtype=torch.float32)  # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ PyTorch —Ç–µ–Ω–∑–æ—Ä
        mask = torch.tensor(mask, dtype=torch.long)  # –ú–∞—Å–∫–∞ –≤ long (–¥–ª—è CrossEntropyLoss)

        return img, mask
